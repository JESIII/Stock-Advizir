{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import fnmatch\r\n",
    "import datetime\r\n",
    "from datetime import datetime\r\n",
    "import json\r\n",
    "import pandas as pd\r\n",
    "from joblib import dump, load\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from finta import TA\r\n",
    "#from sklearn.ensemble import RandomForestClassifier\r\n",
    "#from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "import time\r\n",
    "import requests\r\n",
    "alpha_vantage_key = None\r\n",
    "fmp_key_1 = None\r\n",
    "fmp_key = None\r\n",
    "def add_ratings_to_data(df: pd.DataFrame):\r\n",
    "    shift = 30 #30 days, 6.5 hrs/day, 2 half-hrs/hr\r\n",
    "    df['rating'] = 'hold'\r\n",
    "    df.loc[((df['open'] < df.shift(shift)['open']) & ((df.shift(shift)['open'] - df['open']) / df['open'] * 100 > 10)), 'rating'] = 'mega buy'\r\n",
    "    df.loc[((df['open'] < df.shift(shift)['open']) & ((df.shift(shift)['open'] - df['open']) / df['open'] * 100 > 2)), 'rating'] = 'buy'\r\n",
    "    df.loc[((df['open'] > df.shift(shift)['open']) & ((df['open'] - df.shift(shift)['open']) / df['open'] * 100 > 10)), 'rating'] = 'mega sell'\r\n",
    "    df.loc[((df['open'] > df.shift(shift)['open']) & ((df['open'] - df.shift(shift)['open']) / df['open'] * 100 > 2)), 'rating'] = 'sell'\r\n",
    "    return df\r\n",
    "\r\n",
    "def train():\r\n",
    "    # screen stocks into sectors, market cap sizes\r\n",
    "    small_cap_url = f'https://financialmodelingprep.com/api/v3/stock-screener?marketCapMoreThan=300000000&marketCapLowerThan=2000000001&limit=3&apikey={fmp_key}'\r\n",
    "    mid_cap_url = f'https://financialmodelingprep.com/api/v3/stock-screener?marketCapMoreThan=2000000000&marketCapLowerThan=10000000001&limit=3&apikey={fmp_key}'\r\n",
    "    large_cap_url = f'https://financialmodelingprep.com/api/v3/stock-screener?marketCapMoreThan=10000000000&limit=3&apikey={fmp_key}'\r\n",
    "    # find api that can screen by those\r\n",
    "\r\n",
    "    # https://api-v2.intrinio.com/securities/screen\r\n",
    "    # need to have top 3 of each sector(aka GICS group)/market cap pair\r\n",
    "    training_stocks = {\r\n",
    "        'Consumer Cyclical':[],\r\n",
    "        'Energy':[],\r\n",
    "        'Technology':[],\r\n",
    "        'Industrials':[],\r\n",
    "        'Financial Services':[],\r\n",
    "        'Basic Materials':[],\r\n",
    "        'Communication Services':[],\r\n",
    "        'Consumer Defensive':[],\r\n",
    "        'Healthcare':[],\r\n",
    "        'Real Estate':[],\r\n",
    "        'Utilities':[],\r\n",
    "        'Industrial Goods':[],\r\n",
    "        'Financial':[],\r\n",
    "        'Services':[],\r\n",
    "        'Conglomerates':[]\r\n",
    "    }\r\n",
    "    for sector in training_stocks:\r\n",
    "        url = small_cap_url + f'&sector={sector}'\r\n",
    "        r = requests.get(url)\r\n",
    "        data = r.json()\r\n",
    "        for stock in data:\r\n",
    "            training_stocks[sector].append(stock['symbol'])\r\n",
    "        url = mid_cap_url + f'&sector={sector}'\r\n",
    "        r = requests.get(url)\r\n",
    "        data = r.json()\r\n",
    "        for stock in data:\r\n",
    "            training_stocks[sector].append(stock['symbol'])\r\n",
    "        url = large_cap_url + f'&sector={sector}'\r\n",
    "        r = requests.get(url)\r\n",
    "        data = r.json()\r\n",
    "        for stock in data:\r\n",
    "            training_stocks[sector].append(stock['symbol'])\r\n",
    "        time.sleep(1)\r\n",
    "    # alpha vantage for stock data\r\n",
    "\r\n",
    "    # we need take into account: \r\n",
    "    # sentiment, country, rsi, macd, \r\n",
    "    # earnings date, price, volume, fear index of overall market\r\n",
    "\r\n",
    "    for sector in training_stocks:\r\n",
    "        stocks = training_stocks[sector]\r\n",
    "        for stock in stocks:\r\n",
    "            data = get_and_clean_data(stock)\r\n",
    "            data = add_ratings_to_data(data)\r\n",
    "            data.dropna(inplace=True)\r\n",
    "            category = get_stock_category(stock)\r\n",
    "            x = data.drop(['open', 'high', 'low', 'close', 'volume', 'rating'], axis=1)\r\n",
    "            y = data['rating']\r\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=1337)\r\n",
    "            classifier = KNeighborsClassifier()\r\n",
    "            classifier.fit(X_train, y_train)\r\n",
    "            y_pred = classifier.predict(X_test)\r\n",
    "            accuracy = metrics.accuracy_score(y_test, y_pred)\r\n",
    "            stats_str = f'Classifier: {category}_{stock}\\nAccuracy: {accuracy}\\n----------------------\\n'\r\n",
    "            file_name = f'{category}_{stock}'\r\n",
    "            print(stats_str)\r\n",
    "            open(f'./stats/{file_name}.txt', \"w\").write(stats_str)\r\n",
    "            dump(classifier, f'./classifiers/{file_name}.classifier', compress=True)\r\n",
    "            # when in predictor, run all 3 for each sector/cap and do majority voting to choose the result\r\n",
    "def get_and_clean_data(stock):\r\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&datatype=csv&adjusted=true&symbol={stock}&outputsize=full&apikey={alpha_vantage_key}'\r\n",
    "    data = pd.read_csv(url, index_col='timestamp')\r\n",
    "    data_price = data.copy()\r\n",
    "    data_rsi = TA.STOCHRSI(data)\r\n",
    "    data_macd = TA.MACD(data)\r\n",
    "    data_stoch = TA.STOCH(data)\r\n",
    "    data_vzo = TA.VZO(data)\r\n",
    "    url = f'https://www.alphavantage.co/query?function=CCI&time_period=60&datatype=csv&symbol={stock}&interval=daily&apikey={alpha_vantage_key}'\r\n",
    "    data_cci = pd.read_csv(url, index_col='time')\r\n",
    "    url = f'https://www.alphavantage.co/query?function=CONSUMER_SENTIMENT&datatype=csv&apikey={alpha_vantage_key}'\r\n",
    "    data_sent = pd.read_csv(url, index_col='timestamp')\r\n",
    "    # url = f'https://www.alphavantage.co/query?function=UNEMPLOYMENT&datatype=csv&apikey={alpha_vantage_key}'\r\n",
    "    # data_unemployment = pd.read_csv(url, index_col='timestamp')\r\n",
    "    data = data.join(data_rsi, how='left') \r\n",
    "    data = data.join(data_macd, how='left') \r\n",
    "    data = data.join(data_stoch, how='left') \r\n",
    "    data = data.join(data_vzo, how='left') \r\n",
    "    data = data.join(data_cci, how='left') \r\n",
    "    data = data.join(data_sent, how='left')\r\n",
    "    # data = data.join(data_unemployment, how='left')\r\n",
    "    data = data.drop(labels=['open', 'high', 'low', 'close', 'volume'], axis=1)\r\n",
    "    scaler = preprocessing.MinMaxScaler() \r\n",
    "    scaled_values = scaler.fit_transform(data) \r\n",
    "    data.loc[:,:] = scaled_values\r\n",
    "    data = data.join(data_price, how='left')\r\n",
    "    data.interpolate(axis='columns', inplace=True)\r\n",
    "    data.dropna(inplace=True)\r\n",
    "    return data\r\n",
    "def get_stock_category(stock):\r\n",
    "    url = f'https://financialmodelingprep.com/api/v3/profile/{stock}?apikey={fmp_key}'\r\n",
    "    data = requests.get(url).json()\r\n",
    "    sector = data[0]['sector']\r\n",
    "    cap = data[0]['mktCap']\r\n",
    "    if cap > 10_000_000_000:\r\n",
    "        cap = 'large'\r\n",
    "    elif cap < 10_000_000_000 and cap > 2_000_000_000:\r\n",
    "        cap = 'mid'\r\n",
    "    else:\r\n",
    "        cap = 'small'\r\n",
    "    sector = sector.replace(' ', '')\r\n",
    "    category = f'{sector}_{cap}'\r\n",
    "    return category\r\n",
    "def predict(stock):\r\n",
    "    data = get_and_clean_data(stock)\r\n",
    "    category = get_stock_category(stock)\r\n",
    "    ratings = {\r\n",
    "        'mega buy':0,\r\n",
    "        'buy':0,\r\n",
    "        'hold':0,\r\n",
    "        'mega sell':0,\r\n",
    "        'sell':0\r\n",
    "    }\r\n",
    "    for filename in os.listdir('./classifiers'):\r\n",
    "        if fnmatch.fnmatch(filename, f'{category}*'):\r\n",
    "            classifier : KNeighborsClassifier = load(filename)\r\n",
    "            prediction = classifier.predict(data)\r\n",
    "            ratings[prediction['rating']] += 1\r\n",
    "    if list(ratings.values).count(max(ratings, key=ratings.get)) > 1:\r\n",
    "        return 1 # 1 == Hold\r\n",
    "    else:\r\n",
    "        return max(ratings, key=ratings.get)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "interpreter": {
   "hash": "3492b37776baa321d60e96246898095570d8f7b7d66331de0f37549c95074a41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}